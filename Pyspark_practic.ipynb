{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1GZBgvirloxDyRoSsYjJ9OrG1J-2MCjl3",
      "authorship_tag": "ABX9TyMb1gQVNjcwvCPPnTMjMCTc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rushabhbhagat08/Pyspark/blob/main/Pyspark_practic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Learn Pyspark"
      ],
      "metadata": {
        "id": "-_bMx9zokpkW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Installation Of pyspark Library"
      ],
      "metadata": {
        "id": "-5hCZVYwkzxT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYzqrfkjxKbX",
        "outputId": "11ce246b-df63-4c76-ce45-ad93712f8248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=962131f5bf9f183254fcd7351b616cfc27327d4795fe10fa6cc5ac8af90c4548\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "#installation pyspark library\n",
        "! pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import pyspark freamwork\n",
        "import pyspark"
      ],
      "metadata": {
        "id": "SsuOGZjTbkZ6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create a pyspark secession"
      ],
      "metadata": {
        "id": "sxpp9GoDpffU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import sparksession from pyspark\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "H6p2W8vmorGt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build session\n",
        "spark=SparkSession.builder.appName('pyspark_practise').getOrCreate()"
      ],
      "metadata": {
        "id": "I0NhBEOpp2-y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#see the session\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "xaIGXpUxqdN6",
        "outputId": "a3f9cf75-311d-4934-f2f9-f0c7e794f969"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x77fdcffada80>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://6423842b03b2:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark_practise</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we are create a pyspark seeeion our app name is Pyspark_practise. Here we execute a local machine so, there is only one cluster but when we execute in a cloud there are number of clusters. The spark version we use that is V3.5.0."
      ],
      "metadata": {
        "id": "UGUfvr-bqp2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Reading the Dataset"
      ],
      "metadata": {
        "id": "fxPuqbGwrw68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# upload the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Qc6-T1ueUvb",
        "outputId": "a1d161bf-877a-42c7-f9d8-72546a8528a4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read the file from drive\n",
        "df_pyspark=spark.read.csv(\"/content/drive/MyDrive/Pyspark/Pyspark_demo.csv\")"
      ],
      "metadata": {
        "id": "qSOq_4_Eqg6K"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see tthe dataset\n",
        "df_pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILzFVGWVr-aN",
        "outputId": "2f731c09-0c47-4767-d2fd-888d764f4ef8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[_c0: string, _c1: string, _c2: string]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Pyspark Dataframe"
      ],
      "metadata": {
        "id": "h-wF338Sge9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# overview of the dataset\n",
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGx56IsrsG8r",
        "outputId": "d598b090-77df-46a2-9098-6ab1b0bdc378"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----+----------+\n",
            "|           _c0| _c1|       _c2|\n",
            "+--------------+----+----------+\n",
            "| Employee name|Age |Experience|\n",
            "|Mayur Kalamkar|  25|        10|\n",
            "| Sharad Dhole |  26|        20|\n",
            "|Rushabh Bhagat|  26|         5|\n",
            "+--------------+----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now in this data fream show the two columns i.e. C0 and C1. But its show the C0 and C1 as a header so, we modified that header lets see the new command."
      ],
      "metadata": {
        "id": "RzwDXiPYtUQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fixed the header of the dataset\n",
        "spark.read.option('header','true').csv('/content/drive/MyDrive/Pyspark/Pyspark_demo.csv').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBLrAWDgsJxo",
        "outputId": "97b74854-d1bc-4cd4-d3e3-d7876271fcab"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----+----------+\n",
            "| Employee name|Age |Experience|\n",
            "+--------------+----+----------+\n",
            "|Mayur Kalamkar|  25|        10|\n",
            "| Sharad Dhole |  26|        20|\n",
            "|Rushabh Bhagat|  26|         5|\n",
            "+--------------+----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_pyspark=spark.read.option('header','true').csv('/content/drive/MyDrive/Pyspark/Pyspark_demo.csv')"
      ],
      "metadata": {
        "id": "O7-T6bZVuZt5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Types of dataFrame"
      ],
      "metadata": {
        "id": "Gwx29agJuqsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# type of the dataframe\n",
        "type(df_pyspark)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJaHwb6eumHK",
        "outputId": "17319276-56ef-443c-e200-d04527a99fff"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### show the top rows in dataframe"
      ],
      "metadata": {
        "id": "ocorGEY4vI_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# top 3 rows in dataframe\n",
        "df_pyspark.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBzIGrnTu5GK",
        "outputId": "4c18af37-f9c6-4d1c-866c-681e93c1ac84"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Employee name='Mayur Kalamkar', Age ='25', Experience='10'),\n",
              " Row(Employee name='Sharad Dhole ', Age ='26', Experience='20'),\n",
              " Row(Employee name='Rushabh Bhagat', Age ='26', Experience='5')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Checking Datatype and columns"
      ],
      "metadata": {
        "id": "b2G4Afu0gzqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# information about dataset\n",
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjvvItU1vSj6",
        "outputId": "b350bbdc-171b-4591-d2e4-28bc55a24cf0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Employee name: string (nullable = true)\n",
            " |-- Age : string (nullable = true)\n",
            " |-- Experience: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It gives the information about your dataset.But now here to see the Age and Experience columns is integer datatype but its show string. so, there is a option in csv i.e. inferscheme this by default false so it show the all values are string datatype."
      ],
      "metadata": {
        "id": "RiCFkxzWviAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using a options\n",
        "df_pyspark=spark.read.options(inferSchema=True,header=True).csv('/content/drive/MyDrive/Pyspark/Pyspark_demo.csv')"
      ],
      "metadata": {
        "id": "ACu6oxE7vZjJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we use options() it means it gives a multiple arguments but in option() take  single arguments. **Note: inferSchema not work in option().**"
      ],
      "metadata": {
        "id": "UqZsxV_20kmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# show the informaation of the dataset\n",
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_Z3Nt0uxfk5",
        "outputId": "2e95cc65-7ee3-4c93-a1fb-e95dd5d08059"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Employee name: string (nullable = true)\n",
            " |-- Age : integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Another Way"
      ],
      "metadata": {
        "id": "kp40EHqA1VVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#another way to using inferSchema\n",
        "df_pyspark=spark.read.csv('/content/drive/MyDrive/Pyspark/Pyspark_demo.csv',header=True,inferSchema=True)"
      ],
      "metadata": {
        "id": "_vJ9QRdfzV5f"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show the informaation of the dataset\n",
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkzgYRs51pAz",
        "outputId": "fdf9aec7-fd69-40bf-8e35-0a40da8da991"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Employee name: string (nullable = true)\n",
            " |-- Age : integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the columns name in our dataset\n",
        "df_pyspark.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mkgdHSR1rlA",
        "outputId": "78d6196a-a255-4d6d-e524-7aad9739cb48"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Employee name', 'Age ', 'Experience']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# select a perticular colums and see the datatype of that\n",
        "df_pyspark.select('Employee Name')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNJ9FSvY1_fG",
        "outputId": "511b71db-97a8-4765-904c-1197a1973434"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Employee Name: string]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#show a first colums\n",
        "df_pyspark.select('Employee name').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inm2X2MF2XQK",
        "outputId": "350d0c2e-cac7-4bd2-ef90-5092801ca505"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+\n",
            "| Employee name|\n",
            "+--------------+\n",
            "|Mayur Kalamkar|\n",
            "| Sharad Dhole |\n",
            "|Rushabh Bhagat|\n",
            "+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now pick a multiple columns\n",
        "df_pyspark.select(['Employee Name', 'Experience']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvvKQBNy2yqL",
        "outputId": "2cee416f-785e-43e2-8da7-2abfcc0fcea1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----------+\n",
            "| Employee Name|Experience|\n",
            "+--------------+----------+\n",
            "|Mayur Kalamkar|        10|\n",
            "| Sharad Dhole |        20|\n",
            "|Rushabh Bhagat|         5|\n",
            "+--------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show the datatype of the dataframe\n",
        "df_pyspark.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmc0XQJo3Kw6",
        "outputId": "f7f33b08-88f3-43c4-8233-babc4ebf6cb1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Employee name', 'string'), ('Age ', 'int'), ('Experience', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding the columns"
      ],
      "metadata": {
        "id": "Udkh0vvfhBHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adding column in the datafream\n",
        "df_pyspark.withColumn('Experience After 2 years',df_pyspark['Experience']+2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LaILN3sNUiV",
        "outputId": "fe832c64-8cdd-437c-d6d4-4e00d78cedb7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----+----------+------------------------+\n",
            "| Employee name|Age |Experience|Experience After 2 years|\n",
            "+--------------+----+----------+------------------------+\n",
            "|Mayur Kalamkar|  25|        10|                      12|\n",
            "| Sharad Dhole |  26|        20|                      22|\n",
            "|Rushabh Bhagat|  26|         5|                       7|\n",
            "+--------------+----+----------+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Droping the columns"
      ],
      "metadata": {
        "id": "C9v46xNuhEEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# delate column from datafream\n",
        "df_pyspark.drop('Experience After 2 years').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvmCS21UOV1O",
        "outputId": "90eed0ec-583d-4c9e-a90a-ef8c4b293e5e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----+----------+\n",
            "| Employee name|Age |Experience|\n",
            "+--------------+----+----------+\n",
            "|Mayur Kalamkar|  25|        10|\n",
            "| Sharad Dhole |  26|        20|\n",
            "|Rushabh Bhagat|  26|         5|\n",
            "+--------------+----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Renaming  column\n",
        "df_pyspark.withColumnRenamed('Employee Name','Name').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_OZS4DUQYIK",
        "outputId": "80cf53ba-ef2b-4046-cd20-e991766c745a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----+----------+\n",
            "|          Name|Age |Experience|\n",
            "+--------------+----+----------+\n",
            "|Mayur Kalamkar|  25|        10|\n",
            "| Sharad Dhole |  26|        20|\n",
            "|Rushabh Bhagat|  26|         5|\n",
            "+--------------+----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eS4K02B4RD2g"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}